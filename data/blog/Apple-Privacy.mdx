---
title: Apple doesn't care about privacy, and it's showing.
date: '2022-07-06'
tags: [apple, tech, privacy]
draft: false
summary: Apple announced that it would begin checking content uploaded to iCloud Photos, against a list of known CSAM material. This is fine on it's own, however the system could easily be abused.
---

<img className="inline" src="/static/images/Blog/apple-privacy.jpg" alt="Apple Privacy" />

A few days ago, Apple announced that it would begin checking content uploaded to iCloud Photos - the company's photo backup/synchronization service - against a list of known CSAM material. **This is fine on it's own**, however the system could easily be abused.

So what happens when a government says “We want you to add these hashes of government-critical memes to your database”? Apple [says](https://www.apple.com/child-safety/pdf/Expanded_Protections_for_Children_Frequently_Asked_Questions.pdf) they would “refuse such demands”, I doubt they could.

One of the first issues I noticed is with their marketing. Apple is arguing that, because the detection happens on your device, as opposed to on their servers, it's more privacy-friendly. But Apple can already view uploaded data, iCloud does not use end-to-end encryption - in fact, they even [dropped plans](https://www.reuters.com/article/us-apple-fbi-icloud-exclusive-idUSKBN1ZK1CT) to do so after the FBI complained.

This is all further evidence that Apple only cares about privacy when they can market it. Explaining to the average consumer that you use “end-to-end encryption” doesn't increase sales; most people don't even know what that means. And if it doesn't increase sales, why even bother in the first place?

> The only way to guarantee that such a powerful tool isn't abused and doesn't fall into the wrong hands is to never create it.

\- Apple, [2016](https://www.apple.com/customer-letter/answers/)
